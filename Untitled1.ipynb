{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#urllib is used to download the utils file from deeplearning.net\n",
    "#import urllib\n",
    "#response = urllib.urlopen('http://deeplearning.net/tutorial/code/utils.py')\n",
    "#content = response.read()\n",
    "#target = open('utils.py', 'w')\n",
    "#target.write(content)\n",
    "#target.close()\n",
    "#Import the math function for calculations\n",
    "import math\n",
    "#Tensorflow library. Used to implement machine learning models\n",
    "import tensorflow as tf\n",
    "#Numpy contains helpful functions for efficient mathematical calculations\n",
    "import numpy as np\n",
    "#Image library for image manipulation\n",
    "#from PIL import Image\n",
    "#import Image\n",
    "#Utils file\n",
    "#from utils import tile_raster_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Class that defines the behavior of the RBM\n",
    "class RBM(object):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        #Defining the hyperparameters\n",
    "        self._input_size = input_size #Size of input\n",
    "        self._output_size = output_size #Size of output\n",
    "        self.epochs = 5 #Amount of training iterations\n",
    "        self.learning_rate = 0.1 #The step used in gradient descent\n",
    "        self.batchsize = 100 #The size of how much data will be used for training per sub iteration\n",
    "        \n",
    "        #Initializing weights and biases as matrices full of zeroes\n",
    "        self.w = np.zeros([input_size, output_size], np.float32) #Creates and initializes the weights with 0\n",
    "        self.hb = np.zeros([output_size], np.float32) #Creates and initializes the hidden biases with 0\n",
    "        self.vb = np.zeros([input_size], np.float32) #Creates and initializes the visible biases with 0\n",
    "\n",
    "\n",
    "    #Fits the result from the weighted visible layer plus the bias into a sigmoid curve\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        #Sigmoid \n",
    "        return tf.nn.tanh(tf.matmul(visible, w) + hb)\n",
    "\n",
    "    #Fits the result from the weighted hidden layer plus the bias into a sigmoid curve\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.nn.tanh(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
    "    \n",
    "    #Generate the sample probability\n",
    "    def sample_prob(self, probs):\n",
    "        return tf.nn.tanh(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "\n",
    "    #Training method for the model\n",
    "    def train(self, X):\n",
    "        #Create the placeholders for our parameters\n",
    "        _w = tf.placeholder(\"float\", [self._input_size, self._output_size])\n",
    "        _hb = tf.placeholder(\"float\", [self._output_size])\n",
    "        _vb = tf.placeholder(\"float\", [self._input_size])\n",
    "        \n",
    "        prv_w = np.zeros([self._input_size, self._output_size], np.float32) #Creates and initializes the weights with 0\n",
    "        prv_hb = np.zeros([self._output_size], np.float32) #Creates and initializes the hidden biases with 0\n",
    "        prv_vb = np.zeros([self._input_size], np.float32) #Creates and initializes the visible biases with 0\n",
    "\n",
    "        \n",
    "        cur_w = np.zeros([self._input_size, self._output_size], np.float32)\n",
    "        cur_hb = np.zeros([self._output_size], np.float32)\n",
    "        cur_vb = np.zeros([self._input_size], np.float32)\n",
    "        v0 = tf.placeholder(\"float\", [None, self._input_size])\n",
    "        \n",
    "        #Initialize with sample probabilities\n",
    "        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb))\n",
    "        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb))\n",
    "        h1 = self.prob_h_given_v(v1, _w, _hb)\n",
    "        \n",
    "        #Create the Gradients\n",
    "        positive_grad = tf.matmul(tf.transpose(v0), h0)\n",
    "        negative_grad = tf.matmul(tf.transpose(v1), h1)\n",
    "        \n",
    "        #Update learning rates for the layers\n",
    "        update_w = _w + self.learning_rate *(positive_grad - negative_grad) / tf.to_float(tf.shape(v0)[0])\n",
    "        update_vb = _vb +  self.learning_rate * tf.reduce_mean(v0 - v1, 0)\n",
    "        update_hb = _hb +  self.learning_rate * tf.reduce_mean(h0 - h1, 0)\n",
    "        \n",
    "        #Find the error rate\n",
    "        err = tf.reduce_mean(tf.square(v0 - v1))\n",
    "        \n",
    "        #Training loop\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            #For each epoch\n",
    "            for epoch in range(self.epochs):\n",
    "                #For each step/batch\n",
    "                for start, end in zip(range(0, len(X), self.batchsize),range(self.batchsize,len(X), self.batchsize)):\n",
    "                    batch = X[start:end]\n",
    "                    #Update the rates\n",
    "                    cur_w = sess.run(update_w, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    prv_w = cur_w\n",
    "                    prv_hb = cur_hb\n",
    "                    prv_vb = cur_vb\n",
    "                error=sess.run(err, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb})\n",
    "                print('Epoch: %d' % epoch,'reconstruction error: %f' % error)\n",
    "            self.w = prv_w\n",
    "            self.hb = prv_hb\n",
    "            self.vb = prv_vb\n",
    "\n",
    "    #Create expected output for our DBN\n",
    "    def rbm_outpt(self, X):\n",
    "        input_X = tf.constant(X)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        out = tf.nn.tanh(tf.matmul(input_X, _w) + _hb)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class NN(object):\n",
    "    \n",
    "    def __init__(self, sizes, X, Y):\n",
    "        #Initialize hyperparameters\n",
    "        self._sizes = sizes\n",
    "        self._X = X\n",
    "        self._Y = Y\n",
    "        self.w_list = []\n",
    "        self.b_list = []\n",
    "        self._learning_rate =  0.05\n",
    "        self._momentum = 0.8\n",
    "        self._epoches = 50\n",
    "        self._batchsize = 100\n",
    "        input_size = X.shape[1]\n",
    "        \n",
    "        #initialization loop\n",
    "        for size in self._sizes + [Y.shape[1]]:\n",
    "            #Define upper limit for the uniform distribution range\n",
    "            max_range = 4 * math.sqrt(6. / (input_size + size))\n",
    "            \n",
    "            #Initialize weights through a random uniform distribution\n",
    "            self.w_list.append(\n",
    "                np.random.uniform( -max_range, max_range, [input_size, size]).astype(np.float32))\n",
    "            \n",
    "            #Initialize bias as zeroes\n",
    "            self.b_list.append(np.zeros([size], np.float32))\n",
    "            input_size = size\n",
    "      \n",
    "    #load data from rbm\n",
    "    def load_from_rbms(self, dbn_sizes,rbm_list):\n",
    "        #Check if expected sizes are correct\n",
    "        assert len(dbn_sizes) == len(self._sizes)\n",
    "        \n",
    "        for i in range(len(self._sizes)):\n",
    "            #Check if for each RBN the expected sizes are correct\n",
    "            assert dbn_sizes[i] == self._sizes[i]\n",
    "        \n",
    "        #If everything is correct, bring over the weights and biases\n",
    "        for i in range(len(self._sizes)):\n",
    "            self.w_list[i] = rbm_list[i].w\n",
    "            self.b_list[i] = rbm_list[i].hb\n",
    "\n",
    "    #Training method\n",
    "    def train(self, test_X, test_y, score_function):\n",
    "        #Create placeholders for input, weights, biases, output\n",
    "        _a = [None] * (len(self._sizes) + 2)\n",
    "        _w = [None] * (len(self._sizes) + 1)\n",
    "        _b = [None] * (len(self._sizes) + 1)\n",
    "        _a[0] = tf.placeholder(\"float\", [None, self._X.shape[1]])\n",
    "        y = tf.placeholder(\"float\", [None, self._Y.shape[1]])\n",
    "        \n",
    "        #Define variables and activation functoin\n",
    "        for i in range(len(self._sizes) + 1):\n",
    "            _w[i] = tf.Variable(self.w_list[i])\n",
    "            _b[i] = tf.Variable(self.b_list[i])\n",
    "        for i in range(1, len(self._sizes) + 2):\n",
    "            _a[i] = tf.nn.tanh(tf.matmul(_a[i - 1], _w[i - 1]) + _b[i - 1])\n",
    "        \n",
    "        #Define the cost function\n",
    "        #cost = tf.reduce_mean(tf.square(_a[-1] - y))\n",
    "        cost = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=_a[-1])\n",
    "        \n",
    "        #Define the training operation (Momentum Optimizer minimizing the Cost function)\n",
    "        train_op = tf.train.MomentumOptimizer(\n",
    "            self._learning_rate, self._momentum).minimize(cost)\n",
    "        \n",
    "        #Prediction operation\n",
    "        #predict_op = tf.argmax(_a[-1], 1)\n",
    "        predict_op = _a[-1]\n",
    "        \n",
    "        #Training Loop\n",
    "        with tf.Session() as sess:\n",
    "            #Initialize Variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            #For each epoch\n",
    "            for i in range(self._epoches):\n",
    "                \n",
    "                #For each step\n",
    "                for start, end in zip(\n",
    "                    range(0, len(self._X), self._batchsize), range(self._batchsize, len(self._X), self._batchsize)):\n",
    "                    \n",
    "                    #Run the training operation on the input data\n",
    "                    sess.run(train_op, feed_dict={\n",
    "                        _a[0]: self._X[start:end], y: self._Y[start:end]})\n",
    "                    \n",
    "                    #print(sess.run(cost, feed_dict={_a[0]: self._X[start:end], y: self._Y[start:end]}))\n",
    "                \n",
    "                for j in range(len(self._sizes) + 1):\n",
    "                    #Retrieve weights and biases\n",
    "                    self.w_list[j] = sess.run(_w[j])\n",
    "                    self.b_list[j] = sess.run(_b[j])\n",
    "                    #print(self.w_list[j])\n",
    "                \n",
    "                \n",
    "                ytr_pred = sess.run(predict_op, feed_dict={_a[0]: self._X, y: self._Y})                \n",
    "                print(\"ytr_pred: \",ytr_pred, np.sum(np.argmax(ytr_pred, axis=1)))\n",
    "                \n",
    "                ytt_pred = sess.run(predict_op, feed_dict={_a[0]: test_X, y: test_y})\n",
    "                print(\"ytt_pred: \", np.sum(np.argmax(ytt_pred, axis=1)))\n",
    "                print(\"Accuracy rating for epoch \" + str(i) + \": \" + str(np.sum(np.argmax(self._Y, axis=1) ==\n",
    "                              np.argmax(ytr_pred, axis=1))))\n",
    "                \n",
    "                score_train=score_function(np.argmax(self._Y,axis=1),np.argmax(ytr_pred, axis=1))\n",
    "                print(score_train)\n",
    "                score_test=score_function(np.argmax(test_y,1),np.argmax(ytt_pred,1))\n",
    "                print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "problem = imp.load_source('', 'problem.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = problem.get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = problem.get_test_data(path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3465 1155\n"
     ]
    }
   ],
   "source": [
    "train_is, test_is = list(problem.get_cv(X_train, y_train))[0]\n",
    "print(len(train_is), len(test_is))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts_fe, reg = problem.workflow.train_submission(\n",
    "    'submissions/starting_kit', X_train, y_train, train_is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "xtr_norm=normalize(ts_fe.transform(X_train),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtt_norm=normalize(ts_fe.transform(X_test),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtr = ts_fe.transform(X_train)\n",
    "xtt = ts_fe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr=np.array([y_train,1-y_train])\n",
    "y_tt=np.array([y_test,1-y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<xarray.DataArray 'enstime' (enstime: 4620)>\n",
       " array([(0, 334.0), (0, 699.0), (0, 1064.0), ..., (3, 420814.0), (3, 421179.0),\n",
       "        (3, 421544.0)], dtype=object)\n",
       " Coordinates:\n",
       "   * enstime  (enstime) MultiIndex\n",
       "   - ens      (enstime) int64 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
       "   - time     (enstime) float64 334.0 699.0 1.064e+03 1.429e+03 1.794e+03 ...,\n",
       " array([ 24.66748238,  15.30056095,  18.51390266, ..., -11.5751152 ,\n",
       "         66.05991364,  54.38762665], dtype=float32))"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['TS']['enstime'], xtr[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_function = problem.score_types[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4620, 60), (4620, 60), (4620, 60))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr_norm.shape, xtr.shape, xtt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4620,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.5, n_estimators=20, random_state=None)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=2), learning_rate=0.5, n_estimators=20)\n",
    "clf.fit(xtr_norm, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytt_pred = clf.predict(xtt_norm)\n",
    "ytr_pred = clf.predict(xtr_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(ytr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.7529022634412108, -4.5095351914732094)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_function(ytr_pred, y_train), score_function(ytt_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBM:  0   60 -> 50\n",
      "RBM:  1   50 -> 150\n"
     ]
    }
   ],
   "source": [
    "RBM_hidden_sizes = [50, 150] #create 2 layers of RBM with size 400 and 100\n",
    "\n",
    "#Since we are training, set input as training data\n",
    "inpX = xtr_norm\n",
    "\n",
    "#Create list to hold our RBMs\n",
    "rbm_list = []\n",
    "\n",
    "#Size of inputs is the number of inputs in the training set\n",
    "input_size = inpX.shape[1]\n",
    "\n",
    "#For each RBM we want to generate\n",
    "for i, size in enumerate(RBM_hidden_sizes):\n",
    "    print('RBM: ',i,' ',input_size,'->', size)\n",
    "    rbm_list.append(RBM(input_size, size))\n",
    "    input_size = size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New RBM:\n",
      "WARNING:tensorflow:From <ipython-input-4-64999e8cb468>:67: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch: 0 reconstruction error: 0.595960\n",
      "Epoch: 1 reconstruction error: 0.597049\n",
      "Epoch: 2 reconstruction error: 0.596340\n",
      "Epoch: 3 reconstruction error: 0.596398\n",
      "Epoch: 4 reconstruction error: 0.595573\n",
      "New RBM:\n",
      "WARNING:tensorflow:From <ipython-input-4-64999e8cb468>:67: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch: 0 reconstruction error: 0.851083\n",
      "Epoch: 1 reconstruction error: 0.632991\n",
      "Epoch: 2 reconstruction error: 0.672517\n",
      "Epoch: 3 reconstruction error: 0.578385\n",
      "Epoch: 4 reconstruction error: 0.702503\n"
     ]
    }
   ],
   "source": [
    "#For each RBM in our list\n",
    "for rbm in rbm_list:\n",
    "    print('New RBM:')\n",
    "    #Train a new one\n",
    "    rbm.train(inpX) \n",
    "    #Return the output layer\n",
    "    inpX = rbm.rbm_outpt(inpX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytr_pred:  [[-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " ..., \n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 0: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 1: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 2: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 3: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 4: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 5: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 6: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 7: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 8: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 9: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 10: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 11: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 12: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 13: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " ..., \n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 14: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 15: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 16: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 17: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 18: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " ..., \n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 19: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " ..., \n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 20: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " ..., \n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 21: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " ..., \n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 22: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " ..., \n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 23: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 24: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 25: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 26: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 27: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 28: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " ..., \n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 29: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 30: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " ..., \n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 31: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 32: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " ..., \n",
      " [-1.  1.]\n",
      " [-1.  1.]\n",
      " [-1.  1.]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 33: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 34: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 35: 4107\n",
      "-0.124908692476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 36: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 37: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 38: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 39: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 40: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 41: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 42: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 43: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 44: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 45: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 46: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 47: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999976  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 48: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n",
      "ytr_pred:  [[-0.99999988  1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " ..., \n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]\n",
      " [-1.          1.        ]] 4620\n",
      "ytt_pred:  4620\n",
      "Accuracy rating for epoch 49: 4107\n",
      "-0.124908692476\n",
      "-0.106586826347\n"
     ]
    }
   ],
   "source": [
    "nNet = NN(RBM_hidden_sizes, xtr_norm, y_tr.T)\n",
    "nNet.load_from_rbms(RBM_hidden_sizes,rbm_list)\n",
    "nNet.train(xtt_norm,y_tt.T, score_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_function(np.argmax(y_tr.T,axis=1), np.argmax(y_tr.T,axis=1))\n",
    "#np.sum(y_train == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = np.array([[0.98,0.99],[0.97,0.96],[0.98,0.97],[0.98,0.99]])\n",
    "arg = np.argmax(ar,axis=1)\n",
    "np.array([arg==0,arg==1], dtype=int).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ar>0.5, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
